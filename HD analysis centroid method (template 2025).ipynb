{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Analysis for the H-D Spectrum Experiment (2025)\n",
    "\n",
    "## Centroid method\n",
    "\n",
    "This template uses a \"centroid\" calculation to obtain the peak locations.\n",
    "\n",
    "Use this template to carry out the analysis tasks for the experiment.  You may need to consult the documentation for different Python packages.  Also recommended: the [Whirlwind Tour of Python](https://jakevdp.github.io/WhirlwindTourOfPython/) and the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) both by Jake VanderPlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, import some packages\n",
    "\n",
    "This is a good idea at the beginning of your notebook to include the packages that you will need.  We will use the four shown below here.  A brief description:\n",
    "* `numpy` is the foundational package for Python numerical work. It extends and speeds up array operations beyond standard Python, and it includes almost all math functions that you would need for example `sqrt()` (square root) or `cos()` (cosine).  These would be written in code as `np.sqrt()` or `np.cos()`.\n",
    "* `scipy` is a huge collection of scientific data analysis functions, routines, physicical constants, etc.  This is the second most used package for scientific work. Documentation is at [SciPy.org](https://docs.scipy.org/doc/scipy/reference/) with the constants subpackage at https://docs.scipy.org/doc/scipy/reference/constants.html.\n",
    "* `uncertainties` is a very useful small package that simplifies uncertainty propagation and printing out of quantities with uncertainty.  Documentation is at https://pythonhosted.org/uncertainties/\n",
    "* `matplotlib` is *the* standard plotting package for scientific Python.  We will use a subset called `pyplot` which is modeled after the plotting functions used in MATLAB. The last line below, `%matplotlib inline`, simply forces the plots to appear within the notebook.\n",
    "* `pandas` is a large data science package.  It's main feature is a set of methods to create and manipulate \"Dataframes\", which is an enlargement of the idea of an array.  It plays well with NumPy and other packages.  We will use it mainly as a way to read files into data sets in an easy way.\n",
    "\n",
    "We will also be using the [**LMFit**](https://lmfit.github.io/lmfit-py/) curve fitting package.  This library is very powerful and relatively easy to use to perform complex fitting of functions to data sets, and to also extract meaningful values for statistical uncertainties in the fitting parameters.  It will be introduced and imported later in the template.  Documentation is at https://lmfit.github.io/lmfit-py/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell with Shift-Enter, and wait until the asterisk changes to a number, i.e., [*] becomes [1]\n",
    "import numpy as np\n",
    "import scipy.constants as const\n",
    "import uncertainties as unc\n",
    "import uncertainties.unumpy as up\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Calibration\n",
    "\n",
    "### Read in the data\n",
    "\n",
    "It is always a good idea to make a plot of the raw data before trying to manipulate it. Before doing this, you should open a data file with a simple text editor to see what it looks like.  You will see some information at the beginning about the oscilloscope's parameters.\n",
    "\n",
    "Then use the **Pandas** function `read_csv()` to pull the file into a Pandas Dataframe, like this:\n",
    "\n",
    "```\n",
    "Na = pd.read_csv('Na_D_lines.csv')\n",
    "```\n",
    "\n",
    "If the last line in the cell is the name of the dataframe, it will print a nice table.\n",
    "\n",
    "You may obtain the arrays for each column by using the column label, e.g., `Na['X']` is the array of the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines allow the user to enter a data file\n",
    "\n",
    "Na = pd.read_csv('Na_D_lines_LVChartRec.csv')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just using the label alone causes the dataframe to be displayed.  \n",
    "# You may also use display(DataFrame_name) to show the table anytime\n",
    "\n",
    "# The \"[:10]\" truncates the view to the first 10 rows.\n",
    "\n",
    "display(Na[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "Below, I show how. Study the commands, change them, and see what happens.  Hint: study the sections in the [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) on Matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid()\n",
    "plt.title('Na Calibration scan')\n",
    "plt.ylabel(r'Intensity (V)')\n",
    "plt.xlabel(r'Time (s)')\n",
    "plt.plot(Na['X'],Na[' Y0'],'-',label='Na D-lines')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate the peak maxima\n",
    "\n",
    "There are two parts to this.  Part 1 is to smooth the data, Part 2 is to locate the maxima of the smoothed data and the width of the peaks located under the maxima.\n",
    "\n",
    "**NOTE: You may skip the smoothing step if you have already smoothed the data with the Chart Recorder application.  Go directly to Part 2.**\n",
    "\n",
    "To do this we will need two functions from SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import functions from SciPy's collection.  You only need to do an import once in a given session\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Smooth data sets** First, you want to smooth the y-axis (voltage) data a little bit.  Look closely at the plot, and you will notics a kind of \"stairstep\" quality, especially near the baseline.  This is the limit of the digitization resolution. Smoothing the data a small amount will remove much of this and make it easier to see the shape of the curve.\n",
    "\n",
    "One way is to use \"Gaussian filtering\" to do this.  Gaussian filtering uses a gaussian to convolve with the data set.  The numerical parameter parameter gives the width of the gaussian; larger widths mean more smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing with a parameter of 5\n",
    "# This way of doing it adds another column to the dataframe.\n",
    "Na['Y0_smoothed'] = gaussian_filter1d(Na[' Y0'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting the smoothed data over the original data.  Then change the `5` in the `gaussian_filter1d()` function to `100` and see what happens.  **Message:** Be careful with smoothing data sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid()\n",
    "plt.title('Na Calibration scan')\n",
    "plt.ylabel(r'Intensity (V)')\n",
    "plt.xlabel(r'Time (s)')\n",
    "plt.plot(Na['X'],Na[' Y0'],'-',label='Na D-lines')\n",
    "plt.plot(Na['X'],Na['Y0_smoothed'],'-',label='Smoothed data')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2.** Second, you can use a peak-finding function from SciPy.  This will locate the array indices of peaks in the data sets that satisfy certain criteria.  Using this function takes some care.  You should plot the peak locations and other parameters you are trying to find to make sure it is doing what you want.\n",
    "\n",
    "I show an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assign current arrays to xdata, ydata\n",
    "ydata = Na['Y0_smoothed'] # Or Na['']\n",
    "xdata = Na['X']\n",
    "\n",
    "# A \"min width\" keeps small fluctuations near the top from being labeled separate peaks\n",
    "# Width units are array indices.  You may need to change this, depending on how closely spaced \n",
    "# your data points are.\n",
    "min_width = 50\n",
    "\n",
    "# Below does the work.  The height parameter makes the function only look \n",
    "# for peaks higher than halfway up the tallest peak.\n",
    "peaks, pk_props = find_peaks(ydata, width = min_width, height = ydata.max()/2.)\n",
    "\n",
    "for pk, prop in zip(peaks, pk_props['widths']): \n",
    "    print('Peak at {:d} has width {:.1f}'.format(pk, prop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show this with a plot.  Note the use of vlines() and hlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid()\n",
    "plt.title('Na Calibration scan')\n",
    "plt.ylabel(r'Intensity (V)')\n",
    "plt.xlabel(r'Array index')\n",
    "plt.plot(ydata,'-',label='Smoothed data')\n",
    "plt.vlines(x=peaks, ymin=0, ymax=ydata[peaks], color='C2', label='Locations')\n",
    "plt.hlines(y=pk_props['width_heights'], xmin=peaks-pk_props['widths']/2, \n",
    "           xmax=peaks+pk_props['widths']/2, color = 'C1', label='Widths')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now save the peak positions and widths.  These will be used to determine either starting values for a peak-fitting routine or to determine the centroid of each peak.  I will show how to do either of these calculations, starting with the centroid finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na_peaks = peaks\n",
    "Na_widths = pk_props['widths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cull a slice for each peak\n",
    "\n",
    "# 'extent' is a multiplier of width to get the full peak\n",
    "extent = 2.5\n",
    "\n",
    "# pk_indices is a list of the lists if integers corresponing to the indices within a peak\n",
    "\n",
    "pk_indices = []\n",
    "for pk, width in zip(Na_peaks, Na_widths): \n",
    "    # The folowing statement is a Python \"list comprehension\".  It is like a loop in compact form\n",
    "    # data.size is the length of the data array.  This collects all of the indicies that lie in a certain range\n",
    "    indices = [i for i in range(ydata.size) if (i > pk-extent*width) and (i < pk+extent*width)]\n",
    "    # Add the list of indices to the bigger list. \n",
    "    pk_indices.append(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid()\n",
    "plt.title('Na Calibration scan, Isolated peaks')\n",
    "plt.ylabel(r'Intensity (V)')\n",
    "plt.xlabel(r'Array Index')\n",
    "for pk, indices in zip(peaks, pk_indices):\n",
    "        plt.plot(ydata[indices],'-', label='Peak at {:d}'.format(pk))\n",
    "plt.vlines(x=peaks, ymin=0, ymax=ydata[peaks], color='C2', label='Locations')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis next.\n",
    "\n",
    "The goal is to calculate a centroid. The centroid is the weighted average of the x position:\n",
    "\n",
    "$$ x_\\text{cent} = \\frac{\\sum x_iy_i}{\\sum y_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calculates centroid and stddev\n",
    "\n",
    "def get_centroid(xdata,ydata):\n",
    "    # calculate weighted average of x-position\n",
    "    mid = np.sum(xdata*ydata)/np.sum(ydata) \n",
    "    return mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `get_centroid()` and the location of the peak maximum to get the peak location and an uncertainty, defined as the difference between the centrod and the peak maximum.\n",
    "\n",
    "Save the result into an uncertainty object `ufloat`.\n",
    "\n",
    "Calculations with uncertainty objects will automatically propagate the uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Peak_loc = []\n",
    "\n",
    "for pk, indices in zip(Na_peaks, pk_indices) :\n",
    "    mid_time = get_centroid(xdata[indices],ydata[indices])\n",
    "    max_time = xdata[pk]\n",
    "    peak_time = unc.ufloat(mid_time, np.abs(max_time - mid_time))\n",
    "    Peak_loc.append(peak_time)\n",
    "    print('Peak at index {:d} = {:.2uP} s'.format(pk,peak_time))\n",
    "\n",
    "Na_loc = Peak_loc.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the calibration constant with its uncertainty.  This is easy if you are using the uncertainty object.\n",
    "\n",
    "The calibration constant $K_\\text{Na}$ is simply\n",
    "\n",
    "$$ K_\\text{Na} = \\frac{\\lambda_{\\text{D}_1}-\\lambda_{\\text{D}_2}}{t_{\\text{D}_1}-t_{\\text{D}_2}}$$\n",
    "\n",
    "By definition, $D_1$ has a longer wavelength than $D_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = 5895.92 # Angstroms\n",
    "D2 = 5889.95 # Angstroms\n",
    "\n",
    "## You write this.  Create a calibration constant with uncertainty\n",
    "\n",
    "print('Calibration constant from centroid method: {:.2uP} A/s'.format(K_Na))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data reduction\n",
    "\n",
    "### Read in and plot all of the data\n",
    "\n",
    "Before doing any calculations, you shoul always plot and look hard at your data.\n",
    "\n",
    "Repeat the steps at the beginning to feed each data set into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Collect all the data sets into active dataframes. \n",
    "## Follow the method used for the Na lines\n",
    "\n",
    "## Recommended names  for the dataframes 'Alpha', 'Beta', 'Gamma', etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot all on one graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(Na['X'],Na[' Y0'],'-',label='Na D-lines')\n",
    "plt.plot(Alpha['X'],Alpha[' Y0'],'-',label=r'$\\alpha$')\n",
    "\n",
    "# ....\n",
    "# add the rest here\n",
    "\n",
    "plt.xlabel(r'Time (s)')\n",
    "plt.ylabel(r'Ch 1 (V)')\n",
    "plt.legend()\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to read.  Offset the plots by adding constants to each array, and rescale them by multiplying a constant with each array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cut and paste above, and then manipulate arrays within the plot() calls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process each data file\n",
    "\n",
    "At this point, you want to apply the same basic steps to each H-D spectrum files, namely:\n",
    "\n",
    "* Smooth it.\n",
    "* Locate the peak positions and widths.\n",
    "* Use this information to calculate the centroids.\n",
    "* Determine a position and uncertainty for each peak in the data file.\n",
    "* Calculate $\\Delta t_\\text{HD}$ for the file, and save it.\n",
    "\n",
    "Before doing these steps, convert the code blocks used to carry out these tasks to functions.  This will make your code reuse less messy and easier to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to locate the peaks, plot them, and return the important data\n",
    "\n",
    "def find_and_plot_peaks(ydata, title='Data', makeplot=True):\n",
    "    '''\n",
    "    Function locates peaks using SciPy.signal find_peaks() and plots\n",
    "    the results (optionally).  Returns two arrays: 'peaks' which holds\n",
    "    the index of each peak maximum and 'widths' which holds the FWHM of\n",
    "    each peak.\n",
    "    '''\n",
    "    # You fill this in here  \n",
    "    \n",
    "    return peaks, pk_props['widths']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to obtain lists of indices spanning each peak\n",
    "\n",
    "def select_peak_indices(ydata, peaks, widths, title='Data', extent=2.5, makeplot=True):\n",
    "    '''\n",
    "    Function uses peak finding result to build a list of indices that \n",
    "    span each peak according to the 'extent' parameter.  Optionally plots\n",
    "    the result.  Returns a list of lists.\n",
    "    '''\n",
    "    \n",
    "    # You fill this in here\n",
    "    \n",
    "    return pk_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_peak_locs(xdata, ydata, peaks, peak_indices):\n",
    "    '''\n",
    "    Function uses peaks array and lists of indices to calculate\n",
    "    centroids of each peak in units of the 'xdata' array.  \n",
    "    Returns a list of uncertainty objects whil each value being the centroid \n",
    "    and each uncertainty being the difference between the peak maximum location\n",
    "    and the centroid.\n",
    "    '''\n",
    "    \n",
    "    # You fill this in here\n",
    "    \n",
    "    return Peak_loc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the above.  Recommend commenting out later lines and examining the return values at each step\n",
    "\n",
    "Na_pks, Na_widths = find_and_plot_peaks(ydata, title='Na Lines', makeplot=True)\n",
    "Na_test_indices = select_peak_indices(ydata, Na_pks, Na_widths, title='Na lines')\n",
    "Na_test_loc = calculate_peak_locs(xdata, ydata, Na_pks, Na_test_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the functions\n",
    "\n",
    "Work on Alpha first.  Below I show the first example. Re-use `xdata`, `ydata`, `peaks`, and `widths` to save typing.  **But be careful:** if you execute cells out of sequence, you will get peculiar results!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Prepare the Alpha lines\n",
    "Alpha['Y0_smoothed'] = gaussian_filter1d(Alpha[' Y0'], 5)\n",
    "\n",
    "xdata = Alpha['X']\n",
    "ydata = Alpha['Y0_smoothed']\n",
    "\n",
    "## Execute the first function\n",
    "peaks, widths = find_and_plot_peaks(ydata, title='Alpha Line', makeplot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: isolate peaks and calculate.\n",
    "\n",
    "One may need to adjust the `extent` parameter.\n",
    "\n",
    "Results saved to `Alpha_loc`.  Will repeat for `Beta_loc`, `Gamma_loc`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute the second and third functions\n",
    "indices = select_peak_indices(ydata, peaks, widths, extent=2.3, title='Alpha Line')\n",
    "Alpha_loc = calculate_peak_locs(xdata, ydata, peaks, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for other lines.  \n",
    "\n",
    "Beta next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beta['Y0_smoothed'] = gaussian_filter1d(Beta[' Y0'], 5)\n",
    "\n",
    "xdata = Beta['X']\n",
    "ydata = Beta['Y0_smoothed']\n",
    "\n",
    "## Etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second and third calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You what to do now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Epsilon if you have it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the time differences\n",
    "\n",
    "One easy way is to make a simple Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_T = [Alpha_loc[1]-Alpha_loc[0],\n",
    "      Beta_loc[1]-Beta_loc[0],\n",
    "      Gamma_loc[1]-Gamma_loc[0],\n",
    "      Delta_loc[1]-Delta_loc[0],\n",
    "      Eps1_loc[1]-Eps1_loc[0],\n",
    "      Eps2_loc[1]-Eps2_loc[0]]\n",
    "D_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier way is to build a Pandas Series.  I also average two epsilon runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_T = pd.Series({'Alpha': Alpha_loc[1]-Alpha_loc[0],\n",
    "                   'Beta': Beta_loc[1]-Beta_loc[0],\n",
    "                   'Gamma': Gamma_loc[1]-Gamma_loc[0],\n",
    "                   'Delta': Delta_loc[1]-Delta_loc[0],\n",
    "                   'Epsilon': (Eps1_loc[1]+Eps2_loc[1]-Eps1_loc[0]-Eps2_loc[0])/2.0})\n",
    "Delta_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then include the known hydrogen wavelengths $\\lambda_\\text{H}$.  A table can be found in Haken & Wolf, p.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_H = pd.Series({'Alpha': 6562.79,\n",
    "                   'Beta': 4863.33,\n",
    "                   'Gamma': 4340.46,\n",
    "                   'Delta': 4101.73,\n",
    "                   'Epsilon': 3970.07})\n",
    "lambda_H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD_results = pd.DataFrame({'lambda_H (A)':lambda_H, 'Delta-t (s)': Delta_T})\n",
    "HD_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD_results['Delta-lambda (A)'] = HD_results['Delta-t (s)']*K_Na\n",
    "HD_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a plot\n",
    "\n",
    "Plot the results of $\\Delta t_\\text{HD}$ versus $\\lambda_\\text{H}$ with the uncertainty as errorbars.  Include the origin in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid()\n",
    "plt.title('HD spectrum results')\n",
    "plt.ylim(0,9.8)\n",
    "plt.xlim(0,6800.0)\n",
    "plt.ylabel(r'Time difference between H,D peaks $\\Delta t_{\\rm HD}$ (s)')\n",
    "plt.xlabel(r'Hydrogen wavelength (A)')\n",
    "## up.nominal_values() and up.std_devs() separates out the values and uncertainties from the uncertainty\n",
    "## objects\n",
    "plt.errorbar(HD_results['lambda_H (A)'],up.nominal_values(HD_results['Delta-t (s)']),fmt='o',\n",
    "             yerr=up.std_devs(HD_results['Delta-t (s)']),label='Spectrum data');\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the results\n",
    "\n",
    "To fit the results to a line, make use of the **lmfit** package. It is a useful add-on to the SciPy fitting functions.  This package simplifies fitting data to a variety of standard functions.  See the [Lmfit Documentation](https://lmfit.github.io/lmfit-py/index.html) for a full discussion.  The package is quite powerful, but for basic fitting with common functions, it is very easy to use.  \n",
    "\n",
    "#### Example: Fitting a line\n",
    "\n",
    "The example below shows how to use the package to fit data to a line, obtain the fit parameters along with uncertainties, and then plot the data and fit. Execute the cells and study how it works.\n",
    "(Note: the data come from a calibration problem in physics 331)\n",
    "\n",
    "The first cell is just example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration Data\n",
    "# First column is wavelength (nm), second is carriage poisition (cm)\n",
    "#\n",
    "Cal_data = np.array([\n",
    "    [643.85, 41.43],\n",
    "    [579.07, 37.24],\n",
    "    [576.96, 37.11],\n",
    "    [546.08, 35.10],\n",
    "    [508.58, 32.68],\n",
    "    [479.99, 30.83],\n",
    "    [467.81, 30.04],\n",
    "    [435.83, 27.96],\n",
    "    [404.66, 25.98]])\n",
    "\n",
    "# Array slicing separates x (position) and y (wavelength)\n",
    "# Goal of calibration is to be able to feed in a position and obtain a wavelength\n",
    "wavelength = Cal_data[:,0]\n",
    "position = Cal_data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the fitting example.  Note the very first command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a linear fitting model from lmfit\n",
    "# You only need to execute this line once!\n",
    "from lmfit.models import LinearModel\n",
    "\n",
    "# create an instance of the model\n",
    "line = LinearModel()\n",
    "\n",
    "# One must have a guess of the parameters. The guess() method works with most of the standard\n",
    "# lmfit models\n",
    "param_guess = line.guess(wavelength, x=position)\n",
    "\n",
    "# Fix the intercept to zero\n",
    "param_guess['intercept'].value = 0.0\n",
    "param_guess['intercept'].vary = False\n",
    "    \n",
    "# The line below executes the fitting process.  The results are returned to \"line_fit\"\n",
    "line_fit = line.fit(wavelength, param_guess, x=position)\n",
    "\n",
    "# This prints the results in an easy to read form\n",
    "print(line_fit.fit_report())\n",
    "\n",
    "# The parameters and uncertainties are accessible as follows, for example:\n",
    "print('\\nSlope = ',line_fit.params['slope'].value,'+/-',line_fit.params['slope'].stderr)\n",
    "\n",
    "#Then you can plot the results quickly just to see how it looks using the plot() method\n",
    "line_fit.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the above to your data set. The intercept will vary by default, but because the theory says the relationship is a direct ratio, the intercept should be fixed to zero.  You can do this by setting and freezing the `intercept` parameter before running the fit.  Modify the code above as follows:\n",
    "\n",
    "Put this between the lines that start with `param_guess` and `line_fit`\n",
    "\n",
    "    # Fix the intercept to zero\n",
    "    param_guess['intercept'].value = 0.0\n",
    "    param_guess['intercept'].vary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put the data into simple arrays: xdata, ydata, yuncert\n",
    "\n",
    "xdata = HD_results['lambda_H (A)']\n",
    "ydata = up.nominal_values(HD_results['Delta-t (s)'])\n",
    "yuncert = up.std_devs(HD_results['Delta-t (s)'])\n",
    "\n",
    "## Then use the above code starting with \"param_guess = line.guess(wavelength, x=position)\"\n",
    "## and change the variable assignments appropriately to make your fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code below makes a fitline you can paste over the data\n",
    "\n",
    "xfit = np.linspace(0,6600,10)\n",
    "yfit = line_fit.eval(line_fit.params, x=xfit)\n",
    "\n",
    "## Cut and paste the earlier plot, and include the fitline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the slope from the fit.\n",
    "HD_slope = unc.ufloat(line_fit.params['slope'].value,line_fit.params['slope'].stderr)\n",
    "\n",
    "## Then use it in a calculation to obtain the mass ratio and uncertainty, and print it out\n",
    "\n",
    "## You write code to calculate the mass ratio.\n",
    "\n",
    "print('Calculated Mass ratio of hydrogen/deuterium = {:.1uP}'.format(mass_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
